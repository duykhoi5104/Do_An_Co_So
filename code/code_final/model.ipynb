{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Load embeddings\n",
    "train = np.load(\"train_embeddings.npz\")\n",
    "X_train, y_train = train[\"X\"], train[\"y\"]\n",
    "\n",
    "test = np.load(\"test_embeddings.npz\")\n",
    "X_test, y_test = test[\"X\"], test[\"y\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả mô hình SVM:\n",
      "Accuracy: 1.0\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Duy Khôi       1.00      1.00      1.00         2\n",
      "        Dũng       1.00      1.00      1.00         2\n",
      "      Dương       1.00      1.00      1.00        16\n",
      "          Hà       1.00      1.00      1.00         2\n",
      "       Hiếu       1.00      1.00      1.00        24\n",
      "        Hưng       1.00      1.00      1.00         2\n",
      "         Khôi       1.00      1.00      1.00         2\n",
      "        Lành       1.00      1.00      1.00         6\n",
      "         Linh       1.00      1.00      1.00        36\n",
      "        Luân       1.00      1.00      1.00         3\n",
      "       Nghĩa       1.00      1.00      1.00         3\n",
      "       Nguyên       1.00      1.00      1.00         9\n",
      "Nhật Tiến       1.00      1.00      1.00         2\n",
      "         Phú       1.00      1.00      1.00         5\n",
      "     Phương       1.00      1.00      1.00        18\n",
      "        Quang       1.00      1.00      1.00        21\n",
      "        Quân       1.00      1.00      1.00         5\n",
      "         Sang       1.00      1.00      1.00        12\n",
      "  Thanh Bình       1.00      1.00      1.00         2\n",
      "  Thăng Long       1.00      1.00      1.00         5\n",
      "       Tiến       1.00      1.00      1.00         3\n",
      "       Trường       1.00      1.00      1.00         2\n",
      "   Văn Mạnh       1.00      1.00      1.00         6\n",
      "  Văn Tiến       1.00      1.00      1.00         2\n",
      "   Xuân Hải       1.00      1.00      1.00        12\n",
      "        Đức       1.00      1.00      1.00         5\n",
      "\n",
      "     accuracy                           1.00       207\n",
      "    macro avg       1.00      1.00      1.00       207\n",
      " weighted avg       1.00      1.00      1.00       207\n",
      "\n",
      "[!] Số mẫu sai: 0\n",
      "Một số lỗi phổ biến: []\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình SVM\n",
    "svm = SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_acc = accuracy_score(y_test, svm.predict(X_test))\n",
    "# Lưu mô hình\n",
    "joblib.dump(svm, \"model_svm.joblib\")\n",
    "\n",
    "# Dự đoán\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Đánh giá\n",
    "print(\"\\nKết quả mô hình SVM:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Thống kê lỗi\n",
    "wrong = [(true, pred) for true, pred in zip(y_test, y_pred) if true != pred]\n",
    "print(f\"[!] Số mẫu sai: {len(wrong)}\")\n",
    "print(\"Một số lỗi phổ biến:\", Counter(wrong).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kết quả mô hình Random Forest:\n",
      "Accuracy: 0.9951690821256038\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Duy Khôi       1.00      1.00      1.00         2\n",
      "        Dũng       1.00      1.00      1.00         2\n",
      "      Dương       1.00      1.00      1.00        16\n",
      "          Hà       1.00      1.00      1.00         2\n",
      "       Hiếu       0.96      1.00      0.98        24\n",
      "        Hưng       1.00      1.00      1.00         2\n",
      "         Khôi       1.00      0.50      0.67         2\n",
      "        Lành       1.00      1.00      1.00         6\n",
      "         Linh       1.00      1.00      1.00        36\n",
      "        Luân       1.00      1.00      1.00         3\n",
      "       Nghĩa       1.00      1.00      1.00         3\n",
      "       Nguyên       1.00      1.00      1.00         9\n",
      "Nhật Tiến       1.00      1.00      1.00         2\n",
      "         Phú       1.00      1.00      1.00         5\n",
      "     Phương       1.00      1.00      1.00        18\n",
      "        Quang       1.00      1.00      1.00        21\n",
      "        Quân       1.00      1.00      1.00         5\n",
      "         Sang       1.00      1.00      1.00        12\n",
      "  Thanh Bình       1.00      1.00      1.00         2\n",
      "  Thăng Long       1.00      1.00      1.00         5\n",
      "       Tiến       1.00      1.00      1.00         3\n",
      "       Trường       1.00      1.00      1.00         2\n",
      "   Văn Mạnh       1.00      1.00      1.00         6\n",
      "  Văn Tiến       1.00      1.00      1.00         2\n",
      "   Xuân Hải       1.00      1.00      1.00        12\n",
      "        Đức       1.00      1.00      1.00         5\n",
      "\n",
      "     accuracy                           1.00       207\n",
      "    macro avg       1.00      0.98      0.99       207\n",
      " weighted avg       1.00      1.00      0.99       207\n",
      "\n",
      "[!] Số mẫu sai: 1\n",
      "Một số lỗi phổ biến: [(('Khôi', 'Hiếu'), 1)]\n"
     ]
    }
   ],
   "source": [
    "#  Khời tạo mô hình RF\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "joblib.dump(rf, \"model_randomforest.joblib\")\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n Kết quả mô hình Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "wrong = [(true, pred) for true, pred in zip(y_test, y_pred) if true != pred]\n",
    "print(f\"[!] Số mẫu sai: {len(wrong)}\")\n",
    "print(\"Một số lỗi phổ biến:\", Counter(wrong).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "train_dir = \"data_split/train\"\n",
    "test_dir = \"data_split/test\"\n",
    "img_size = (160, 160)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf4 in position 85: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load ảnh thành dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# vì softmax\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     10\u001b[0m     test_dir,\n\u001b[0;32m     11\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimg_size,\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     13\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Loc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:232\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Loc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:531\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    529\u001b[0m subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubdir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    533\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Loc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf4 in position 85: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Load ảnh thành dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'  # vì softmax\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Tối ưu hiệu suất\u001b[39;00m\n\u001b[0;32m      2\u001b[0m AUTOTUNE \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE\n\u001b[1;32m----> 3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mAUTOTUNE)\n\u001b[0;32m      4\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mAUTOTUNE)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Mô hình MobileNetV2 + phân lớp\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Tối ưu hiệu suất\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Mô hình MobileNetV2 + phân lớp\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(train_ds.element_spec[1].shape[-1], activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "mobilenet_acc = history.history[\"val_accuracy\"][-1]  \n",
    "\n",
    "print(f\"Accuracy MobileNetV2: {mobilenet_acc:.4f}\")\n",
    "model.save(\"mobilenetv2_face_recognition.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ biểu đồ so sánh \n",
    "models = ['SVM', 'Random Forest', 'MobileNetV2']\n",
    "accuracies = [svm_acc, rf_acc, mobilenet_acc]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(models, accuracies, color=[\"skyblue\", \"lightgreen\", \"salmon\"])\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"So sánh độ chính xác giữa các mô hình\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f\"{acc:.2%}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
